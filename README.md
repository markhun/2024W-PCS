# 2025 - Project in Computer Science - On the Status Quo of Inter-GPU Communication Libraries

This repository contains code for running a simple runtime benchmark for a simple MPI and Nvidia NCCL program. The benchmark executes a single `Broadcast` operation, executes a simple dummy CUDA kernel, which touches each buffer element exactly once and then executes a `Reduce` operation.

The benchmark measures the runtime of the `Broadcast` and `Reduce` collective operations to allow for a basic comparison between MPI+CUDA and NCCL.

The benchmark itself performs a couple of warm-up runs before performing the actual measurements.

- The top-level [Makefile](Makefile) contains commands necessary to set up a local development environment as well as commands to set up the runtime environment within a container provided by Chameleon Cloud.
- ["Simple MPI bounce buffer"](./simple_mpi_bounce_buffer) contains code and a build system for compiling and running the MPI+CUDA experiment.
- ["Simple NCCL"](./simple_mpi_nccl/) contains the code and build system for compiling and running the NCCL experiment
- Result data for some experiment runs performed on Chameleon cloud can be found within the [Result Directory](./results/).  
This not only includes the collected as CSV, but also the log output generated by the different experiment runs.   
In addition, each experiment documents the hardware setup of the system it was performed on in the form of the outputs of the outputs of `iperf` (Network setup), `lscpu` (Installed CPUs) and `nvidia-smi` (Installed GPUs).
- The result directory also contains a [Python notebook](./results/visualization/plots.ipynb) with some visualizations of the gathered measurements.

## Multi Node experiment on Chameleon Cloud

### 1. Setup SSH keys and SSH Config, so that all nodes can be ssh'ed into.
  
E.g. copy private key to main node and set up `.ssh/config` similar to:  
  
```
Host 129.114.109.229
  HostName 129.114.109.229
  IdentityFile ~/.ssh/cham_ssh_key
  IdentitiesOnly yes
  User cc
```

Chameleon Cloud will ensure that corresponding public key of your used private key was deployed to every node under the `cc` user account during node imaging/deployment.
  
### 2. Execute `make setup-chameleon-cuda2404-container` on every node.
  
This will install all necessary dependencies.  
  
### 3. Compile experiment on main node. 
  
E.g. via executing `make clean; make simple_mpi_bounce_buffer` in `./simple_mpi_bounce_buffer`.  

### 4. Apply the following `firewalld` rules on all nodes:
  
```
    sudo firewall-cmd --zone=trusted --add-source=10.0.0.0/8
    sudo firewall-cmd --zone=trusted --add-source=172.16.0.0/12
    sudo firewall-cmd --zone=trusted --add-source=192.168.0.0/16
    sudo firewall-cmd --runtime-to-permanent
```

This will ensure local network connectivity within the shared network provided by Chameleon Cloud.

### 5. Set up the experiment parameters

Each experiment contains its own `Makefile` with targets to build and execute the experiment:  
  
- [Simple MPI with GPU bounce buffer](./simple_mpi_bounce_buffer/Makefile)
- [Simple NCCL](./simple_mpi_nccl/Makefile)
  
Modify the experiment's `Makefile` with the correct values for `HOSTS` and `SLOTS`.  
`HOSTS` should contain a comma separated list of IP addresses of every node that should be part of the experiment (excluding the main node - localhost). `SLOTS` should contain the number of processes to start per node. This should ideally be the number of GPUs per node.

### 6. Execute the experiment

To execute an experiment on a single node simply run `make local_run`.  
  
To execute an experiment on multiple nodes execute `make distributed_run`  

This will use cluster shell (`clush`) to copy the compiled experiment to every node. 
Then `mpirun` is used to start the experiment on every node.
The run will generate a measurement data file of the format `data_$(RUN_DATETIME).csv` and an additional text file containing the stdout output of the run of the format `output_$(RUN_DATETIME).txt`. The stdout output is also shown on screen while running.  

### 7. Inspect results

Each experiment will write two text files. A file containing the measurement results in CSV format and a file containing the logging output of the run. Both files will contain the date and time of the run within their respective file names.